import json
from openai import OpenAI
from tqdm import tqdm

# ğŸ”‘ API Key ê¼­ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¡œ ì„¤ì •í•´ë‘ì„¸ìš”
client = OpenAI()

def embed_chunks(input_json, output_json, model_name="text-embedding-3-small", batch_size=50):
    # JSON ë¡œë“œ
    with open(input_json, "r", encoding="utf-8") as f:
        data = json.load(f)

    # chunked í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    texts = [item["chunked"] for item in data if item.get("chunked", "").strip()]
    print(f"[INFO] ì´ {len(texts)}ê°œì˜ ì²­í¬ ë²¡í„°í™” ì‹œì‘ (ëª¨ë¸: {model_name})")

    # ê²°ê³¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    embeddings = []

    # OpenAIëŠ” ëŒ€ëŸ‰ ì…ë ¥ë„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ì§€ë§Œ, ì•ˆì „í•˜ê²Œ batch ë‹¨ìœ„ë¡œ ìë¥´ê¸°
    for i in tqdm(range(0, len(texts), batch_size), desc="Batches"):
        batch = texts[i:i+batch_size]
        response = client.embeddings.create(
            model=model_name,
            input=batch
        )
        batch_embeddings = [e.embedding for e in response.data]
        embeddings.extend(batch_embeddings)

    # ë‹¤ì‹œ ë§¤í•‘
    idx = 0
    for item in data:
        if item.get("chunked", "").strip():
            item["vector"] = embeddings[idx]
            idx += 1

    # ì €ì¥
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print("[ì™„ë£Œ] ë²¡í„° ì¶”ê°€ëœ JSON ì €ì¥:", output_json)


if __name__ == "__main__":
    embed_chunks(
        input_json="ê°•ì›ëŒ€í•™êµ ëŒ€í•™ì› í•™ì‚¬ìš´ì˜ê·œì •_chunks.json",
        output_json="ê°•ì›ëŒ€í•™êµ ëŒ€í•™ì› í•™ì‚¬ìš´ì˜ê·œì •_chunks_embedded.json"
    )
